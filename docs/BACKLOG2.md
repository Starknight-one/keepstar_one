# Backlog 2 — Путь к первой сделке

6 шагов к минималке, которую можно продавать. Без лишнего — только то, что блокирует продажу.

---

## Шаг 1 — Структура каталога

### Собрать правильную структуру каталога
**Что:** Пересобрать структуру каталога так, чтобы она подходила под реальные бизнес-кейсы клиентов.
**Зачем:** Каталог — фундамент всего. Кривая структура = кривой поиск, кривой рендер, кривые рекомендации. Без нормального каталога продавать нечего.
**Как:** TODO — описание от автора.
**Бизнес-ценность:** Без этого остальные шаги не имеют смысла.

#### PIM Redesign — схема переведена на типизированные колонки

**Статус:** ✅ Код готов, миграции написаны, не применены к проду.

**Что сделано (2026-02-19):**
- **DROP legacy**: `attributes` (JSONB), `short_name`, `volume`, `inci_text` — удалены из схемы
- **Новые PIM-колонки**: `product_form`, `texture`, `routine_step`, `skin_type[]`, `concern[]`, `key_ingredients[]`, `target_area[]`, `free_from[]`, `marketing_claim`, `benefits[]`, `how_to_use`, `enrichment_version`
- **Volume**: разбит на `volume_ml`, `weight_g`, `unit_count` (парсинг, не LLM)
- **Таблица `ingredients`** + junction `product_ingredients` (INCI, position, is_key)
- **Индексы**: B-tree на scalar, GIN на массивах
- **Digest builder**: переписан с `LATERAL jsonb_each_text` на `UNION ALL` по PIM-колонкам + Query 3 (top-20 ингредиентов по частоте)
- **Domain structs**: `MasterProduct`, `Product` — `Attributes map[string]any` → 17 типизированных полей
- **Catalog search tool**: фильтры с enum-валидацией (`product_form`, `skin_type`, `concern`, `key_ingredient`, `routine_step`, `texture`, `target_area`)
- **Все query-функции** (ListProducts, GetProduct, VectorSearch, services) переписаны под PIM-колонки
- **Миграции** дублированы в оба бэкенда (chat + admin)

**Что осталось (enrichment pipeline):**
1. Применить миграции (запустить серверы → дропнутся 4 legacy-колонки)
2. Пересобрать дайджест для hey-babes
3. Rebuild embeddings из PIM-данных
4. Seed ingredients (запустить seed-ingredients)
5. Удалить мусорный продукт, тест поиска
6. Спроектировать продовый enrichment agent + tools (inline в import pipeline)
7. Перенести парсинг фактов (volume, INCI, how_to_use) в код, не в LLM

---

## Шаг 2 — Сжатие дайджеста

### Прокачать сжатие дайджеста
**Что:** Оптимизировать формирование дайджеста, который передаётся в LLM.
**Зачем:** Меньше токенов = быстрее ответ, дешевле запрос, больше места для полезного контекста.
**Как:** Ревью текущего формата дайджеста, убрать дублирование, сжать структуру, оставить только то, что реально влияет на качество ответа.
**Бизнес-ценность:** Прямое снижение latency и cost per query. На демо скорость — это первое, что замечает клиент.

---

## Шаг 3 — Сжатие контекста истории сообщений

### Убрать дыру в 80k токенов при наличии истории
**Что:** Сейчас при наличии истории сообщений агентам отправляется ~80k токенов контекста. Это убийственно по latency и стоимости. Нужно правильно сжать историю.
**Зачем:** 80k токенов — это несколько секунд latency и $$$. Пользователь не будет ждать 10 секунд на ответ.
**Как:** Проанализировать что именно отправляется, сжать историю (суммаризация / truncation / sliding window). Если сжатие не даёт нужного качества — добавить дополнительный поиск в моменте (retrieval на лету), чтобы компенсировать потерю контекста.
**Бизнес-ценность:** Latency на уровне "мгновенно" — обязательное условие для продажи. Без этого демо выглядит как тормоз.

---

## Шаг 4 — Прокачка поиска + Tool Train

### Тройной гибридный поиск через tool train
**Что:** Переделать тулл поиска на tool train: одновременный запуск 3 гибридных поисков по разным направлениям (разные стратегии / запросы / фильтры).
**Зачем:** Один поиск часто промахивается. Три параллельных поиска по разным осям драматически повышают recall и precision.
**Как:** Tool train: агент формирует 3 параллельных поисковых запроса с разными стратегиями → запуск одновременно → мердж и ранжирование результатов → передача в LLM.
**Бизнес-ценность:** Точность поиска — это core value proposition. Клиент спросил "красное платье до 5000" — и нашёл. Это то, что продаёт.

---

## Шаг 5 — Визуал и кейсы

### Прокачка визуала через реальные кейсы
**Что:** Создать набор тестовых кейсов (реальные сценарии использования), прогонять их, находить и чинить проблемы визуального отображения.
**Зачем:** На демо клиент видит визуал. Кривой рендер, поехавшие карточки, обрезанные картинки = "сырой продукт".
**Как:** Автор готовит кейсы → прогон → анализ что работает / что нет → фиксы. Итеративно, через реальные сценарии.
**Бизнес-ценность:** Визуальное впечатление — второе (после скорости), что замечает клиент на демо.

---

## Шаг 6 — Инфраструктура: БД + LLM + хостинг

### Перевести БД и LLM провайдера на локальных, хостинг
**Что:** Перенести базу данных и LLM провайдера на локальные (ближние) сервера. Выбрать и поднять хостинг.
**Зачем:** Latency сети — главный враг UX. Запрос в Neon US + Anthropic API = сотни мс overhead, которые пользователь чувствует.
**Как:** БД — локальный/ближний PostgreSQL. LLM — провайдер с минимальным latency (возможно РФ провайдер или edge-инстанс). Хостинг — под реальные потребности, без оверинжиниринга.
**Бизнес-ценность:** Latency < 1s на полный цикл ответа — обязательное условие для продажи SaaS-решения. Инфраструктура должна работать, а не тормозить.

---

*Последнее обновление: 2026-02-19*
