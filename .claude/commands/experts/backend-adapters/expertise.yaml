# Backend Adapters Expertise
# Port implementations - external integrations

overview:
  layer: "adapters"
  path: "project/backend/internal/adapters/"
  imports: "domain/, ports/, external libraries"
  contains: "Port implementations"

adapters:
  anthropic:
    directory: "anthropic/"
    files:
      - "anthropic_client.go - LLMPort implementation: Chat, ChatWithTools, ChatWithToolsCached, ChatWithUsage"
      - "cache_types.go - Prompt caching types: cacheControl, contentBlockWithCache, contentBlockFullCache, anthropicToolWithCache, toolChoiceConfig, anthropicCachedRequest (with ToolChoice), anthropicCachedUsage, anthropicCachedResponse"
    implements: "LLMPort"
    status: "implemented"
    api: "POST https://api.anthropic.com/v1/messages"
    env:
      - "ANTHROPIC_API_KEY"
      - "LLM_MODEL (default: claude-haiku-4-5-20251001)"
    pricing:
      haiku: "$1/$5 per 1M tokens (input/output)"
      sonnet: "$3/$15 per 1M tokens"
    prompt_caching:
      method: "ChatWithToolsCached"
      cache_points: ["last tool (cache_control)", "system prompt block (cache_control)", "second-to-last message (cache_control)"]
      types_file: "cache_types.go"
      helpers: ["markMessageCacheControl(msg) — uses contentBlockFullCache to preserve all fields (id, name, input)", "convertToAnthropicMessage(msg)"]
    tool_choice:
      description: "ChatWithToolsCached supports ToolChoice via CacheConfig ('auto'/'any'/'tool:name')"
      types: "toolChoiceConfig { Type, Name } in cache_types.go"
    span_instrumentation:
      description: "Both ChatWithTools and ChatWithToolsCached emit spans via domain.SpanFromContext/StageFromContext"
      spans_emitted:
        - "{stage}.llm — total LLM call time (detail: '{reqKB}KB→{respKB}KB')"
        - "{stage}.llm.ttfb — time-to-first-byte via httptrace.GotFirstResponseByte"
        - "{stage}.llm.body — response body read time"
      slow_ttfb_warning: "Logs [WARN] if TTFB exceeds 10 seconds (ChatWithToolsCached only)"

  postgres:
    directory: "postgres/"
    status: "implemented"
    implements: ["CachePort", "EventPort", "CatalogPort", "StatePort", "TracePort"]
    files:
      - "postgres_client.go - Connection pool (pgxpool)"
      - "postgres_cache.go - CachePort (incl. DeleteSession)"
      - "postgres_events.go - EventPort"
      - "postgres_catalog.go - CatalogPort with product merging + VectorSearch (pgvector cosine, optional VectorFilter), SeedEmbedding, GetMasterProductsWithoutEmbedding, GenerateCatalogDigest, GetCatalogDigest, SaveCatalogDigest, GetAllTenants"
      - "postgres_state.go - StatePort with JSONB"
      - "postgres_trace.go - TracePort: Record (DB + console printTrace with WATERFALL), List, Get"
      - "migrations.go - Chat tables"
      - "catalog_migrations.go - Catalog schema + pgvector extension, embedding vector(384) column, HNSW index, catalog_digest JSONB column"
      - "state_migrations.go - State tables"
      - "trace_migrations.go - pipeline_traces table"
      - "catalog_seed.go - Seed data"
      - "retention.go - RetentionService: periodic cleanup (traces, dead sessions, conversation trim)"
      - "catalog_search_relevance_test.go - CatalogPort search relevance tests"
      - "catalog_digest_test.go - CatalogPort digest generation tests"
      - "catalog_seed_large.go - Large seed data loader (multi-category catalog)"
      - "catalog_seed_large_clothing.go - Clothing category seed data"
      - "catalog_seed_large_shoes.go - Shoes category seed data"
      - "catalog_seed_large_elec_phones.go - Phones category seed data"
      - "catalog_seed_large_elec_audio.go - Audio electronics seed data"
      - "catalog_seed_large_elec_home.go - Home electronics seed data"
      - "catalog_seed_large_services.go - Services category seed data"
      - "postgres_state_test.go - StatePort integration tests"
    schemas:
      public: ["chat_users", "chat_sessions", "chat_messages", "chat_events", "chat_session_state", "chat_session_deltas", "pipeline_traces"]
      catalog: ["tenants", "categories", "master_products", "products"]
    retention:
      struct: "RetentionService"
      config: "RetentionConfig { TraceMaxAge: 48h, DeadSessionMaxAge: 1h, ConversationMaxMsgs: 20, CleanupInterval: 30min }"
      cleanup_tasks:
        - "cleanupTraces — delete pipeline_traces older than TraceMaxAge"
        - "cleanupDeadSessions — delete all data for closed sessions older than DeadSessionMaxAge (FK-safe order)"
        - "trimConversationHistory — keep last N messages in conversation_history JSONB array"
    state_columns:
      chat_session_state: ["id", "session_id", "current_data", "current_meta", "current_template", "view_mode", "view_focused", "view_stack", "conversation_history", "step", "created_at", "updated_at"]
      chat_session_deltas: ["id", "session_id", "step", "trigger", "source", "actor_id", "delta_type", "path", "action", "result", "template", "turn_id", "created_at"]
    add_delta_auto_increment: "Step assigned via COALESCE(MAX(step),0)+1 — no manual step management needed"
    env: "DATABASE_URL=postgresql://user:pass@host/db?sslmode=require"

  openai:
    directory: "openai/"
    files:
      - "embedding_client.go - EmbeddingPort implementation: Embed (batch text→vector via OpenAI API)"
    implements: "EmbeddingPort"
    status: "implemented"
    api: "POST https://api.openai.com/v1/embeddings"
    env:
      - "OPENAI_API_KEY"
      - "EMBEDDING_MODEL (default: text-embedding-3-small)"
      - "EMBEDDING_DIMS (default: 384)"
    struct: "EmbeddingClient { apiKey, model, dims, client }"
    types: ["embeddingRequest", "embeddingResponse"]

  json_store:
    directory: "json_store/"
    file: "json_product_store.go"
    implements: "SearchPort"
    status: "stub"

  memory:
    directory: "memory/"
    file: "memory_cache.go"
    implements: "CachePort"
    status: "deprecated (replaced by postgres)"

gotchas:
  postgres:
    - "FK: chat_session_state.session_id → chat_sessions.id"
    - "FK: chat_session_deltas.session_id → chat_sessions.id"
    - "FK: catalog.products.tenant_id → catalog.tenants.id"
    - "ProductFilter conditions are AND-combined"
    - "Search splits multi-word queries into words with OR matching (each word ILIKE in name/brand)"
    - "VectorSearch uses pgvector cosine distance (<=> operator) on master_products.embedding column"
    - "VectorSearch supports optional VectorFilter for brand/category pre-filtering (WHERE clauses before cosine ranking)"
    - "HNSW index on embedding column for approximate nearest neighbor search"
    - "Dependency: github.com/pgvector/pgvector-go (pgvector.NewVector for query params)"
    - "GenerateCatalogDigest aggregates categories, brands, price ranges, attribute cardinality from catalog data"
    - "Catalog digest stored in tenants.catalog_digest JSONB column (migrationCatalogDigest)"
    - "Large seed data split across multiple files by category (clothing, shoes, electronics, services)"
  anthropic:
    - "API version: 2023-06-01"
    - "Response includes usage.input_tokens, usage.output_tokens"
    - "Prompt caching is GA (Dec 2024) — no beta header needed, just cache_control in request"
    - "Prompt caching needs minimum 4096 tokens for Haiku (20 padding tools provide ~5500 tokens)"
    - "ConversationHistory persisted in postgres via conversation_history JSONB column"
    - "Go encoding/json.Marshal sorts map keys deterministically — cache-stable tool definitions"

naming: "{tech}_{purpose}.go"
