# Backend Adapters Expertise
# Port implementations - external integrations

overview:
  layer: "adapters"
  path: "project/backend/internal/adapters/"
  imports: "domain/, ports/, external libraries"
  contains: "Port implementations"

adapters:
  anthropic:
    directory: "anthropic/"
    files:
      - "anthropic_client.go - LLMPort implementation: Chat, ChatWithTools, ChatWithToolsCached, ChatWithUsage"
      - "cache_types.go - Prompt caching types: cacheControl, contentBlockWithCache, contentBlockFullCache, anthropicToolWithCache, anthropicCachedRequest, anthropicCachedUsage, anthropicCachedResponse"
    implements: "LLMPort"
    status: "implemented"
    api: "POST https://api.anthropic.com/v1/messages"
    env:
      - "ANTHROPIC_API_KEY"
      - "LLM_MODEL (default: claude-haiku-4-5-20251001)"
    pricing:
      haiku: "$1/$5 per 1M tokens (input/output)"
      sonnet: "$3/$15 per 1M tokens"
    prompt_caching:
      method: "ChatWithToolsCached"
      cache_points: ["last tool (cache_control)", "system prompt block (cache_control)", "second-to-last message (cache_control)"]
      types_file: "cache_types.go"
      helpers: ["markMessageCacheControl(msg) — uses contentBlockFullCache to preserve all fields (id, name, input)", "convertToAnthropicMessage(msg)"]

  postgres:
    directory: "postgres/"
    status: "implemented"
    implements: ["CachePort", "EventPort", "CatalogPort", "StatePort", "TracePort"]
    files:
      - "postgres_client.go - Connection pool (pgxpool)"
      - "postgres_cache.go - CachePort (incl. DeleteSession)"
      - "postgres_events.go - EventPort"
      - "postgres_catalog.go - CatalogPort with product merging + VectorSearch (pgvector cosine), SeedEmbedding, GetMasterProductsWithoutEmbedding"
      - "postgres_state.go - StatePort with JSONB"
      - "postgres_trace.go - TracePort: Record (DB + console printTrace), List, Get"
      - "migrations.go - Chat tables"
      - "catalog_migrations.go - Catalog schema + pgvector extension, embedding vector(384) column, HNSW index"
      - "state_migrations.go - State tables"
      - "trace_migrations.go - pipeline_traces table"
      - "catalog_seed.go - Seed data"
      - "retention.go - RetentionService: periodic cleanup (traces, dead sessions, conversation trim)"
      - "catalog_search_test.go - CatalogPort search tests"
      - "postgres_state_test.go - StatePort integration tests"
    schemas:
      public: ["chat_users", "chat_sessions", "chat_messages", "chat_events", "chat_session_state", "chat_session_deltas", "pipeline_traces"]
      catalog: ["tenants", "categories", "master_products", "products"]
    retention:
      struct: "RetentionService"
      config: "RetentionConfig { TraceMaxAge: 48h, DeadSessionMaxAge: 1h, ConversationMaxMsgs: 20, CleanupInterval: 30min }"
      cleanup_tasks:
        - "cleanupTraces — delete pipeline_traces older than TraceMaxAge"
        - "cleanupDeadSessions — delete all data for closed sessions older than DeadSessionMaxAge (FK-safe order)"
        - "trimConversationHistory — keep last N messages in conversation_history JSONB array"
    state_columns:
      chat_session_state: ["id", "session_id", "current_data", "current_meta", "current_template", "view_mode", "view_focused", "view_stack", "conversation_history", "step", "created_at", "updated_at"]
      chat_session_deltas: ["id", "session_id", "step", "trigger", "source", "actor_id", "delta_type", "path", "action", "result", "template", "turn_id", "created_at"]
    add_delta_auto_increment: "Step assigned via COALESCE(MAX(step),0)+1 — no manual step management needed"
    env: "DATABASE_URL=postgresql://user:pass@host/db?sslmode=require"

  openai:
    directory: "openai/"
    files:
      - "embedding_client.go - EmbeddingPort implementation: Embed (batch text→vector via OpenAI API)"
    implements: "EmbeddingPort"
    status: "implemented"
    api: "POST https://api.openai.com/v1/embeddings"
    env:
      - "OPENAI_API_KEY"
      - "EMBEDDING_MODEL (default: text-embedding-3-small)"
      - "EMBEDDING_DIMS (default: 384)"
    struct: "EmbeddingClient { apiKey, model, dims, client }"
    types: ["embeddingRequest", "embeddingResponse"]

  json_store:
    directory: "json_store/"
    file: "json_product_store.go"
    implements: "SearchPort"
    status: "stub"

  memory:
    directory: "memory/"
    file: "memory_cache.go"
    implements: "CachePort"
    status: "deprecated (replaced by postgres)"

gotchas:
  postgres:
    - "FK: chat_session_state.session_id → chat_sessions.id"
    - "FK: chat_session_deltas.session_id → chat_sessions.id"
    - "FK: catalog.products.tenant_id → catalog.tenants.id"
    - "ProductFilter conditions are AND-combined"
    - "Search splits multi-word queries into words with OR matching (each word ILIKE in name/brand)"
    - "VectorSearch uses pgvector cosine distance (<=> operator) on master_products.embedding column"
    - "HNSW index on embedding column for approximate nearest neighbor search"
    - "Dependency: github.com/pgvector/pgvector-go (pgvector.NewVector for query params)"
  anthropic:
    - "API version: 2023-06-01"
    - "Response includes usage.input_tokens, usage.output_tokens"
    - "Prompt caching is GA (Dec 2024) — no beta header needed, just cache_control in request"
    - "Prompt caching needs minimum 4096 tokens for Haiku (20 padding tools provide ~5500 tokens)"
    - "ConversationHistory persisted in postgres via conversation_history JSONB column"
    - "Go encoding/json.Marshal sorts map keys deterministically — cache-stable tool definitions"

naming: "{tech}_{purpose}.go"
