# Backend Implementation Expertise
# Keepstar - Go Hexagonal Architecture

overview:
  description: "Go REST API with hexagonal architecture for AI-powered chat widget"
  architecture: "Hexagonal (Ports & Adapters)"
  language: "Go 1.21+"
  port: 8080
  ai_provider: "Anthropic Claude"
  model: "claude-haiku-4-5-20251001"

project_structure:
  root: "project/backend/"
  entry: "cmd/server/main.go"

  layers:
    domain: "internal/domain/"
    ports: "internal/ports/"
    adapters: "internal/adapters/"
    usecases: "internal/usecases/"
    handlers: "internal/handlers/"
    prompts: "internal/prompts/"
    logger: "internal/logger/"
    config: "internal/config/"

  data: "data/products.json"

layer_rules:
  description: "Dependency direction: handlers → usecases → ports ← adapters, all depend on domain"
  domain:
    imports: "Nothing from internal/"
    contains: "Entities, types, domain errors"
  ports:
    imports: "Only domain/"
    contains: "Interfaces (contracts)"
  usecases:
    imports: "domain/, ports/"
    contains: "Business logic, 1 file = 1 use case"
  adapters:
    imports: "domain/, ports/, external libraries"
    contains: "Port implementations"
  handlers:
    imports: "Everything above + http libraries"
    contains: "HTTP layer, only parse/validate/respond"
  prompts:
    imports: "domain/ (for types)"
    contains: "LLM prompts, separate from logic"

core_implementation:
  main:
    file: "cmd/server/main.go"
    purpose: "Application bootstrap"
    pattern: |
      - Load .env via godotenv
      - Load config
      - Initialize adapters (anthropic)
      - Initialize usecases (sendMessage)
      - Initialize handlers
      - Setup routes
      - Apply CORS middleware
      - Start server

  ports:
    llm_port:
      file: "internal/ports/llm_port.go"
      interface: "LLMPort"
      methods:
        - "Chat(ctx context.Context, message string) (string, error)"

    search_port:
      file: "internal/ports/search_port.go"
      interface: "SearchPort"
      status: "stub"

    cache_port:
      file: "internal/ports/cache_port.go"
      interface: "CachePort"
      status: "stub"

  adapters:
    anthropic:
      file: "internal/adapters/anthropic/anthropic_client.go"
      implements: "LLMPort"
      status: "implemented"
      method: "Chat(ctx, message) (string, error)"
      api: "POST https://api.anthropic.com/v1/messages"

    json_store:
      file: "internal/adapters/json_store/json_product_store.go"
      implements: "SearchPort"
      status: "stub"

    memory:
      file: "internal/adapters/memory/memory_cache.go"
      implements: "CachePort"
      status: "stub"

  usecases:
    chat_send_message:
      file: "internal/usecases/chat_send_message.go"
      struct: "SendMessageUseCase"
      purpose: "Send message to LLM and return response"
      status: "implemented"
      method: "Execute(ctx, message) (string, error)"

  handlers:
    chat:
      file: "internal/handlers/handler_chat.go"
      struct: "ChatHandler"
      endpoint: "POST /api/v1/chat"
      request: "{ message: string }"
      response: "{ response: string }"
      status: "implemented"

    health:
      file: "internal/handlers/handler_health.go"
      endpoints:
        - "GET /health"
        - "GET /ready"

  domain:
    atom_entity:
      file: "internal/domain/atom_entity.go"
      types: ["AtomType", "Atom"]

    widget_entity:
      file: "internal/domain/widget_entity.go"
      types: ["WidgetType", "Widget"]

    formation_entity:
      file: "internal/domain/formation_entity.go"
      types: ["FormationType", "Formation"]

    message_entity:
      file: "internal/domain/message_entity.go"
      types: ["MessageRole", "Message"]

    session_entity:
      file: "internal/domain/session_entity.go"
      types: ["Session"]

    product_entity:
      file: "internal/domain/product_entity.go"
      types: ["Product"]

    domain_errors:
      file: "internal/domain/domain_errors.go"
      errors: ["ErrSessionNotFound", "ErrProductNotFound", "ErrInvalidQuery", "ErrLLMUnavailable"]

api_endpoints:
  chat:
    method: "POST"
    path: "/api/v1/chat"
    body: "{ message: string }"
    response: "{ response: string }"

  health:
    method: "GET"
    path: "/health"
    response: "OK"

  ready:
    method: "GET"
    path: "/ready"
    response: "OK"

patterns:
  naming:
    handlers: "handler_{name}.go"
    usecases: "{domain}_{action}.go"
    adapters: "{tech}_{purpose}.go"
    domain: "{entity}_entity.go"
    ports: "{name}_port.go"
    prompts: "prompt_{name}.go"

  handler_pattern:
    - "Parse request body"
    - "Validate input"
    - "Call use case"
    - "Return JSON response"

  usecase_pattern:
    - "Struct with port dependencies"
    - "NewXxxUseCase() constructor"
    - "Execute(ctx, req) method"

run_commands:
  start: "cd project/backend && go run ./cmd/server/"
  build: "cd project/backend && go build -o server ./cmd/server/"
  test: "cd project/backend && go test ./..."

dependencies:
  - "github.com/joho/godotenv"
  - "github.com/rs/cors"

env_vars:
  required:
    - "ANTHROPIC_API_KEY"
  optional:
    - "PORT (default: 8080)"
    - "ENVIRONMENT (default: development)"
    - "LLM_MODEL (default: claude-haiku-4-5-20251001)"
    - "LOG_LEVEL (default: info)"

migration_status:
  description: "Hexagonal architecture active, simple chat implemented"
  completed:
    - "Migrate to cmd/server/main.go entry point"
    - "Implement LLMPort with Chat method"
    - "Implement Anthropic adapter"
    - "Implement SendMessageUseCase"
    - "Implement ChatHandler"
  next_steps:
    - "Add two-agent pipeline (AnalyzeQuery + ComposeWidgets)"
    - "Implement product search"
    - "Add widget rendering"
